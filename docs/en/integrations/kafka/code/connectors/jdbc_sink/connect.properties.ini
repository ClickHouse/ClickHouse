# bootstrap server - do not include the protocol e.g. pkc-2396y.us-east-1.aws.confluent.cloud:9092
bootstrap.servers=
# The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will
# need to configure these based on the format they want their data in when loaded from or stored into Kafka
key.converter=org.apache.kafka.connect.storage.StringConverter
# we need a schema for the jdbc sink. If not avro, we use the JSONSchemaConverter which ensures each message references a schema in the schema registry
value.converter=io.confluent.connect.json.JsonSchemaConverter
# Converter-specific settings can be passed in by prefixing the Converter's setting with the converter you want to apply it to
key.converter.schemas.enable=false
# set to true if you embed the schema in each message
value.converter.schemas.enable=false

# The internal converter used for offsets and config data is configurable and must be specified, but most users will
# always want to use the built-in default. Offset and config data is never visible outside of Kafka Connect in this format.
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter
internal.key.converter.schemas.enable=false
internal.value.converter.schemas.enable=false

# Store offsets on local filesystem
offset.storage.file.filename=/tmp/connect.offsets
# Flush much faster than normal, which is useful for testing/debugging
offset.flush.interval.ms=10000

ssl.endpoint.identification.algorithm=https
sasl.mechanism=PLAIN
# modify username and password for kafka
sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="<username>" password="<password>";
security.protocol=SASL_SSL

consumer.ssl.endpoint.identification.algorithm=https
consumer.sasl.mechanism=PLAIN
# modify username and password for kafka
consumer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="<username>" password="<password>";
consumer.security.protocol=SASL_SSL

producer.ssl.endpoint.identification.algorithm=https
producer.sasl.mechanism=PLAIN
# modify username and password for kafka
producer.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="<username>" password="<password>";
producer.security.protocol=SASL_SSL

# Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins
# (connectors, converters, transformations).
# Adjust these based on your installation
plugin.path=/usr/share/java,/opt/confluent/confluent-7.0.1/share/filestream-connectors,/opt/confluent/confluent-7.0.1/share/confluent-hub-components,/opt/confluent/confluent-7.0.1/share/confluent-hub-components/lib

# Schema registry configuration
value.converter.basic.auth.credentials.source=USER_INFO
# set authentication key
value.converter.schema.registry.basic.auth.user.info=
# set url for registry - include protocol e.g. https://psrc-1wydj.us-east-2.aws.confluent.cloud
value.converter.schema.registry.url=
