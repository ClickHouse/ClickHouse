---
toc_priority: 79
toc_title: '2017'
---

### ClickHouse Release 1.1.54327, 2017-12-21 {#clickhouse-release-1-1-54327-2017-12-21}

此版本包含`1.1.54318`版本的错误修复:

- 修复了复制中可能导致数据丢失的争用情况错误。此问题影响版本`1.1.54310`和`1.1.54318`。如果对复制表使用这些版本之一，强烈建议进行更新。此问题显示在日志中的警告消息中，如`Part ... from own log doesn't exist.`即使您在日志中没有看到这些消息，问题仍然是存在的。

### ClickHouse Release 1.1.54318, 2017-11-30 {#clickhouse-release-1-1-54318-2017-11-30}

此版本包含`1.1.54310`版本的错误修复:

-   修复了SummingMergeTree引擎中合并期间不正确的行删除
-   修复了未复制的MergeTree引擎中的内存泄漏
-   修复了MergeTree引擎中频繁插入的性能下降问题
-   修复了复制导致队列停止运行的问题
-   修复了服务器日志的归档问题

### ClickHouse Release 1.1.54310, 2017-11-01 {#clickhouse-release-1-1-54310-2017-11-01}

#### New Feature: {#new-features}

-   MergeTree表引擎自定义分区
-   [Kafka](https://clickhouse.tech/docs/en/operations/table_engines/kafka/)表引擎
-   增加了对[CatBoost](https://catboost.yandex/)模型的支持并将其应用于ClickHouse中存储的数据
-   增加了对UTC非整数偏移时区的支持
-   增加了对时间间隔算术运算的支持
-   Date和DateTime类型的值范围扩展到2105年
-   添加`CREATE MATERIALIZED VIEW x TO y`查询(指定用于存储物化视图数据的现有表)
-   添加了不带参数的`ATTACH TABLE`查询
-   SummingMergeTree表引擎中名称以-Map结尾的嵌套列的处理逻辑被提取到sumMap aggregate函数中。现在可以显式指定这些列
-   IP trie字典的最大大小增加到128M
-   添加getSizeOfEnumType函数
-   添加sumWithOverflow聚合函数
-   增加对Cap'n Proto输入格式的支持
-   支持使用zstd算法时自定义压缩级别

#### Backward Incompatible Changes: {#backward-incompatible-changes}

-   不允许使用内存以外的引擎创建临时表
-   不允许使用视图或MaterializedView引擎显式创建表
-   在表创建过程中，检查验证采样表达式是否包含在主键中

#### Bug Fixes: {#bug-fixes}

-   修正了同步插入分布式表时的挂起问题
-   修复了复制表中部件的非原子添加和删除问题
-   插入到物化视图中的数据不会受到不必要的重复数据消除的影响
-   对本地副本滞后且远程副本不可用的分布式表执行查询不会再导致错误
-   用户不再需要对`default`数据库的访问权限来创建临时表
-   修复了指定不带参数的数组类型时的崩溃问题
-   修复了包含服务器日志的磁盘卷已满时的挂起问题
-   修复了Unix epoch第一周的toRelativeWeekNum函数中的溢出问题

#### Build Improvements: {#build-improvements}

-   一些第三方库(尤其是Poco)被更新并转换为git子模块

### ClickHouse Release 1.1.54304, 2017-10-19 {#clickhouse-release-1-1-54304-2017-10-19}

#### New Features: {#new-features-1}

-   本地支持TLS协议(要启用，请在`config.xml`设置`tcp_ssl_port`)

#### Bug Fixes: {#bug-fixes-1}

-   `ALTER` for replicated tables now tries to start running as soon as possible.
-   Fixed crashing when reading data with the setting `preferred_block_size_bytes=0.`
-   Fixed crashes of `clickhouse-client` when pressing `Page Down`
-   Correct interpretation of certain complex queries with `GLOBAL IN` and `UNION ALL`
-   `FREEZE PARTITION` always works atomically now.
-   Empty POST requests now return a response with code 411.
-   Fixed interpretation errors for expressions like `CAST(1 AS Nullable(UInt8)).`
-   Fixed an error when reading `Array(Nullable(String))` columns from `MergeTree` tables.
-   Fixed crashing when parsing queries like `SELECT dummy AS dummy, dummy AS b`
-   Users are updated correctly with invalid `users.xml`
-   Correct handling when an executable dictionary returns a non-zero response code.

### ClickHouse Release 1.1.54292, 2017-09-20 {#clickhouse-release-1-1-54292-2017-09-20}

#### New Features: {#new-features-2}

-   Added the `pointInPolygon` function for working with coordinates on a coordinate plane.
-   Added the `sumMap` aggregate function for calculating the sum of arrays, similar to `SummingMergeTree`.
-   Added the `trunc` function. Improved performance of the rounding functions (`round`, `floor`, `ceil`, `roundToExp2`) and corrected the logic of how they work. Changed the logic of the `roundToExp2` function for fractions and negative numbers.
-   The ClickHouse executable file is now less dependent on the libc version. The same ClickHouse executable file can run on a wide variety of Linux systems. There is still a dependency when using compiled queries (with the setting `compile = 1` , which is not used by default).
-   Reduced the time needed for dynamic compilation of queries.

#### Bug Fixes: {#bug-fixes-2}

-   Fixed an error that sometimes produced `part ... intersects previous part` messages and weakened replica consistency.
-   Fixed an error that caused the server to lock up if ZooKeeper was unavailable during shutdown.
-   Removed excessive logging when restoring replicas.
-   Fixed an error in the UNION ALL implementation.
-   Fixed an error in the concat function that occurred if the first column in a block has the Array type.
-   Progress is now displayed correctly in the system.merges table.

### ClickHouse Release 1.1.54289, 2017-09-13 {#clickhouse-release-1-1-54289-2017-09-13}

#### New Features: {#new-features-3}

-   `SYSTEM` queries for server administration: `SYSTEM RELOAD DICTIONARY`, `SYSTEM RELOAD DICTIONARIES`, `SYSTEM DROP DNS CACHE`, `SYSTEM SHUTDOWN`, `SYSTEM KILL`.
-   Added functions for working with arrays: `concat`, `arraySlice`, `arrayPushBack`, `arrayPushFront`, `arrayPopBack`, `arrayPopFront`.
-   Added `root` and `identity` parameters for the ZooKeeper configuration. This allows you to isolate individual users on the same ZooKeeper cluster.
-   Added aggregate functions `groupBitAnd`, `groupBitOr`, and `groupBitXor` (for compatibility, they are also available under the names `BIT_AND`, `BIT_OR`, and `BIT_XOR`).
-   External dictionaries can be loaded from MySQL by specifying a socket in the filesystem.
-   External dictionaries can be loaded from MySQL over SSL (`ssl_cert`, `ssl_key`, `ssl_ca` parameters).
-   Added the `max_network_bandwidth_for_user` setting to restrict the overall bandwidth use for queries per user.
-   Support for `DROP TABLE` for temporary tables.
-   Support for reading `DateTime` values in Unix timestamp format from the `CSV` and `JSONEachRow` formats.
-   Lagging replicas in distributed queries are now excluded by default (the default threshold is 5 minutes).
-   FIFO locking is used during ALTER: an ALTER query isn’t blocked indefinitely for continuously running queries.
-   Option to set `umask` in the config file.
-   Improved performance for queries with `DISTINCT` .

#### Bug Fixes: {#bug-fixes-3}

-   Improved the process for deleting old nodes in ZooKeeper. Previously, old nodes sometimes didn’t get deleted if there were very frequent inserts, which caused the server to be slow to shut down, among other things.
-   Fixed randomization when choosing hosts for the connection to ZooKeeper.
-   Fixed the exclusion of lagging replicas in distributed queries if the replica is localhost.
-   Fixed an error where a data part in a `ReplicatedMergeTree` table could be broken after running `ALTER MODIFY` on an element in a `Nested` structure.
-   Fixed an error that could cause SELECT queries to “hang”.
-   Improvements to distributed DDL queries.
-   Fixed the query `CREATE TABLE ... AS <materialized view>`.
-   Resolved the deadlock in the `ALTER ... CLEAR COLUMN IN PARTITION` query for `Buffer` tables.
-   Fixed the invalid default value for `Enum` s (0 instead of the minimum) when using the `JSONEachRow` and `TSKV` formats.
-   Resolved the appearance of zombie processes when using a dictionary with an `executable` source.
-   Fixed segfault for the HEAD query.

#### Improved Workflow for Developing and Assembling ClickHouse: {#improved-workflow-for-developing-and-assembling-clickhouse}

-   You can use `pbuilder` to build ClickHouse.
-   You can use `libc++` instead of `libstdc++` for builds on Linux.
-   Added instructions for using static code analysis tools: `Coverage`, `clang-tidy`, `cppcheck`.

#### Please Note When Upgrading: {#please-note-when-upgrading}

-   There is now a higher default value for the MergeTree setting `max_bytes_to_merge_at_max_space_in_pool` (the maximum total size of data parts to merge, in bytes): it has increased from 100 GiB to 150 GiB. This might result in large merges running after the server upgrade, which could cause an increased load on the disk subsystem. If the free space available on the server is less than twice the total amount of the merges that are running, this will cause all other merges to stop running, including merges of small data parts. As a result, INSERT queries will fail with the message “Merges are processing significantly slower than inserts.” Use the `SELECT * FROM system.merges` query to monitor the situation. You can also check the `DiskSpaceReservedForMerge` metric in the `system.metrics` table, or in Graphite. You don’t need to do anything to fix this, since the issue will resolve itself once the large merges finish. If you find this unacceptable, you can restore the previous value for the `max_bytes_to_merge_at_max_space_in_pool` setting. To do this, go to the `<merge_tree>` section in config.xml, set ``` <merge_tree>``<max_bytes_to_merge_at_max_space_in_pool>107374182400</max_bytes_to_merge_at_max_space_in_pool> ``` and restart the server.

### ClickHouse Release 1.1.54284, 2017-08-29 {#clickhouse-release-1-1-54284-2017-08-29}

-   This is a bugfix release for the previous 1.1.54282 release. It fixes leaks in the parts directory in ZooKeeper.

### ClickHouse Release 1.1.54282, 2017-08-23 {#clickhouse-release-1-1-54282-2017-08-23}

This release contains bug fixes for the previous release 1.1.54276:

-   Fixed `DB::Exception: Assertion violation: !_path.empty()` when inserting into a Distributed table.
-   Fixed parsing when inserting in RowBinary format if input data starts with’;’.
-   Errors during runtime compilation of certain aggregate functions (e.g. `groupArray()`).

### ClickHouse Release 1.1.54276, 2017-08-16 {#clickhouse-release-1-1-54276-2017-08-16}

#### New Features: {#new-features-4}

-   Added an optional WITH section for a SELECT query. Example query: `WITH 1+1 AS a SELECT a, a*a`
-   INSERT can be performed synchronously in a Distributed table: OK is returned only after all the data is saved on all the shards. This is activated by the setting insert_distributed_sync=1.
-   Added the UUID data type for working with 16-byte identifiers.
-   Added aliases of CHAR, FLOAT and other types for compatibility with the Tableau.
-   Added the functions toYYYYMM, toYYYYMMDD, and toYYYYMMDDhhmmss for converting time into numbers.
-   You can use IP addresses (together with the hostname) to identify servers for clustered DDL queries.
-   Added support for non-constant arguments and negative offsets in the function `substring(str, pos, len).`
-   Added the max_size parameter for the `groupArray(max_size)(column)` aggregate function, and optimized its performance.

#### Main Changes: {#main-changes}

-   Security improvements: all server files are created with 0640 permissions (can be changed via `<umask>` config parameter).
-   Improved error messages for queries with invalid syntax.
-   Significantly reduced memory consumption and improved performance when merging large sections of MergeTree data.
-   Significantly increased the performance of data merges for the ReplacingMergeTree engine.
-   Improved performance for asynchronous inserts from a Distributed table by combining multiple source inserts. To enable this functionality, use the setting distributed_directory_monitor_batch_inserts=1.

#### Backward Incompatible Changes: {#backward-incompatible-changes-1}

-   Changed the binary format of aggregate states of `groupArray(array_column)` functions for arrays.

#### Complete List of Changes: {#complete-list-of-changes}

-   Added the `output_format_json_quote_denormals` setting, which enables outputting nan and inf values in JSON format.
-   Optimized stream allocation when reading from a Distributed table.
-   Settings can be configured in readonly mode if the value doesn’t change.
-   Added the ability to retrieve non-integer granules of the MergeTree engine in order to meet restrictions on the block size specified in the preferred_block_size_bytes setting. The purpose is to reduce the consumption of RAM and increase cache locality when processing queries from tables with large columns.
-   Efficient use of indexes that contain expressions like `toStartOfHour(x)` for conditions like `toStartOfHour(x) op сonstexpr.`
-   Added new settings for MergeTree engines (the merge_tree section in config.xml):
    -   replicated_deduplication_window_seconds sets the number of seconds allowed for deduplicating inserts in Replicated tables.
    -   cleanup_delay_period sets how often to start cleanup to remove outdated data.
    -   replicated_can_become_leader can prevent a replica from becoming the leader (and assigning merges).
-   Accelerated cleanup to remove outdated data from ZooKeeper.
-   Multiple improvements and fixes for clustered DDL queries. Of particular interest is the new setting distributed_ddl_task_timeout, which limits the time to wait for a response from the servers in the cluster. If a ddl request has not been performed on all hosts, a response will contain a timeout error and a request will be executed in an async mode.
-   Improved display of stack traces in the server logs.
-   Added the “none” value for the compression method.
-   You can use multiple dictionaries_config sections in config.xml.
-   It is possible to connect to MySQL through a socket in the file system.
-   The system.parts table has a new column with information about the size of marks, in bytes.

#### Bug Fixes: {#bug-fixes-4}

-   Distributed tables using a Merge table now work correctly for a SELECT query with a condition on the `_table` field.
-   Fixed a rare race condition in ReplicatedMergeTree when checking data parts.
-   Fixed possible freezing on “leader election” when starting a server.
-   The max_replica_delay_for_distributed_queries setting was ignored when using a local replica of the data source. This has been fixed.
-   Fixed incorrect behavior of `ALTER TABLE CLEAR COLUMN IN PARTITION` when attempting to clean a non-existing column.
-   Fixed an exception in the multiIf function when using empty arrays or strings.
-   修复了反序列化本地格式时内存分配过多的问题
-   修复了Trie字典的不正确自动更新
-   Fixed an exception when running queries with a GROUP BY clause from a Merge table when using SAMPLE.
-   Fixed a crash of GROUP BY when using distributed_aggregation_memory_efficient=1.
-   Now you can specify the database.table in the right side of IN and JOIN.
-   解决了并行聚合的线程太多问题
-   修复了`if`函数处理FixedString参数
-   SELECT worked incorrectly from a Distributed table for shards with a weight of 0. This has been fixed.
-   支持运行`CREATE VIEW IF EXISTS no longer causes crashes.`
-   修复了当输入input_format_skip_unknown_fields=1有负数时的错误行为
-   修复了`dictGetHierarchy()`函数中的无限循环（如果字典中存在无效数据）
-   Fixed `Syntax error: unexpected (...)` errors when running distributed queries with subqueries in an IN or JOIN clause and Merge tables.
-   修复了字典表中SELECT查询的错误描述
-   修复了在包含超过20亿个元素的IN和JOIN子句中使用数组时出现的“Cannot mremap”错误
-   修复了以MySQL为源的字典的故障转移

#### Improved Workflow for Developing and Assembling ClickHouse: {#improved-workflow-for-developing-and-assembling-clickhouse-1}

-   支持在Arcadia上构建
-   可以使用gcc7编译ClickHouse
-   使用ccache+distcc的并行构建更快了

### ClickHouse Release 1.1.54245, 2017-07-04 {#clickhouse-release-1-1-54245-2017-07-04}

#### New Features: {#new-features-5}

-   分布式DDL（例如，`CREATE TABLE ON CLUSTER`）
-   Replicated表支持`ALTER TABLE CLEAR COLUMN IN PARTITION`查询
-   字典表的引擎（以表的形式访问字典数据）
-   字典数据库引擎（这种类型的数据库自动为所有连接的外部字典提供字典表）
-   可以通过向源发送请求来检查字典的更新状态
-   限定列名
-   使用双引号引用标识符
-   HTTP Session 会话接口
-   对于复制表的OPTIMIZE查询不仅可以在leader上运行,还可在其它节点运行

#### Backward Incompatible Changes: {#backward-incompatible-changes-2}

-   移除SET GLOBAL

#### Minor Changes: {#minor-changes}

-   触发警报之后，日志将打印完整的堆栈跟踪
-   在启动时放宽了对损坏/额外数据部分数量的验证（误报太多）

#### Bug Fixes: {#bug-fixes-5}

-   修复了插入分布式表时出现的连接“sticking”问题
-   GLOBAL IN现在适用于查看分布式表的合并表查询
-   在Google计算引擎虚拟机上检测到不正确的内核数。这个问题已经解决了
-   改变缓存的外部字典的可执行源的工作方式
-   修复了包含空字符的字符串的比较问题
-   修复了Float32主键字段与常量的比较问题
-   对字段大小的错误估计可能会导致过大的分配
-   修复了使用ALTER查询添加到表中的可为null的列时发生的崩溃
-   修复了为空的列排序时，如果行数小于限制，出现的崩溃问题
-   修复了仅由常量值组成的ORDER BY子查询
-   删除表失败后，复制表可能会保持无效状态问题
-   带有空结果的标量子查询的别名不再丢失
-   如果.so文件被损坏，使用编译的查询不会因错误而失败
