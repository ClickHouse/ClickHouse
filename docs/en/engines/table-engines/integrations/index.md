---
description: 'Documentation for Table Engines for Integrations'
sidebar_label: 'Integrations'
sidebar_position: 40
slug: /engines/table-engines/integrations/
title: 'Table Engines for Integrations'
doc_type: 'reference'
---

# Table engines for integrations

ClickHouse provides various means for integrating with external systems, including table engines. Like with all other table engines, the configuration is done using `CREATE TABLE` or `ALTER TABLE` queries. Then from a user perspective, the configured integration looks like a normal table, but queries to it are proxied to the external system. This transparent querying is one of the key advantages of this approach over alternative integration methods, like dictionaries or table functions, which require the use of custom query methods on each use.

<!-- The table of contents table for this page is automatically generated by 
https://github.com/ClickHouse/clickhouse-docs/blob/main/scripts/autogenerate-table-of-contents.sh
from the YAML front matter fields: slug, description, title.

If you've spotted an error, please edit the YML frontmatter of the pages themselves.
-->

<!--AUTOGENERATED_START-->
| Page | Description |
|-----|-----|
| [AzureBlobStorage Table Engine](/engines/table-engines/integrations/azureBlobStorage) | This engine provides an integration with Azure Blob Storage ecosystem. |
| [DeltaLake Table Engine](/engines/table-engines/integrations/deltalake) | This engine provides a read-only integration with existing Delta Lake tables in Amazon S3. |
| [EmbeddedRocksDB Engine](/engines/table-engines/integrations/embedded-rocksdb) | This engine allows integrating ClickHouse with RocksDB |
| [ExternalDistributed](/engines/table-engines/integrations/ExternalDistributed) | The `ExternalDistributed` engine allows to perform `SELECT` queries on data that is stored on a remote servers MySQL or PostgreSQL. Accepts MySQL or PostgreSQL engines as an argument so sharding is possible. |
| [TimeSeries Engine](/engines/table-engines/special/time_series) | A table engine storing time series, i.e. a set of values associated with timestamps and tags (or labels). |
| [HDFS](/engines/table-engines/integrations/hdfs) | This engine provides integration with the Apache Hadoop ecosystem by allowing to manage data on HDFS via ClickHouse. This engine is similar to the File and URL engines, but provides Hadoop-specific features. |
| [Hive](/engines/table-engines/integrations/hive) | The Hive engine allows you to perform `SELECT` queries on HDFS Hive table. |
| [Hudi Table Engine](/engines/table-engines/integrations/hudi) | This engine provides a read-only integration with existing Apache Hudi tables in Amazon S3. |
| [Iceberg Table Engine](/engines/table-engines/integrations/iceberg) | This engine provides a read-only integration with existing Apache Iceberg tables in Amazon S3, Azure, HDFS and locally stored tables. |
| [JDBC](/engines/table-engines/integrations/jdbc) | Allows ClickHouse to connect to external databases via JDBC. |
| [Kafka](/engines/table-engines/integrations/kafka) | The Kafka Table Engine can be used to publish works with Apache Kafka and lets you publish or subscribe to data flows, organize fault-tolerant storage, and process streams as they become available. |
| [MaterializedPostgreSQL](/engines/table-engines/integrations/materialized-postgresql) | Creates a ClickHouse table with an initial data dump of a PostgreSQL table and starts the replication process. |
| [MongoDB](/engines/table-engines/integrations/mongodb) | MongoDB engine is read-only table engine which allows to read data from a remote collection. |
| [The MySQL engine allows you to perform `SELECT` and `INSERT` queries on data that is stored on a remote MySQL server.](/engines/table-engines/integrations/mysql) | Documentation for MySQL Table Engine |
| [NATS Engine](/engines/table-engines/integrations/nats) | This engine allows integrating ClickHouse with NATS to publish or subscribe to message subjects, and process new messages as they become available. |
| [ODBC](/engines/table-engines/integrations/odbc) | Allows ClickHouse to connect to external databases via ODBC. |
| [PostgreSQL Table Engine](/engines/table-engines/integrations/postgresql) | The PostgreSQL engine allows `SELECT` and `INSERT` queries on data stored on a remote PostgreSQL server. |
| [RabbitMQ Engine](/engines/table-engines/integrations/rabbitmq) | This engine allows integrating ClickHouse with RabbitMQ. |
| [Redis](/engines/table-engines/integrations/redis) | This engine allows integrating ClickHouse with Redis. |
| [S3 Table Engine](/engines/table-engines/integrations/s3) | This engine provides integration with the Amazon S3 ecosystem. Similar to the HDFS engine, but provides S3-specific features. |
| [AzureQueue Table Engine](/engines/table-engines/integrations/azure-queue) | This engine provides an integration with the Azure Blob Storage ecosystem, allowing streaming data import. |
| [S3Queue Table Engine](/engines/table-engines/integrations/s3queue) | This engine provides integration with the Amazon S3 ecosystem and allows streaming imports. Similar to the Kafka and RabbitMQ engines, but provides S3-specific features. |
| [SQLite](/engines/table-engines/integrations/sqlite) | The engine allows to import and export data to SQLite and supports queries to SQLite tables directly from ClickHouse. |
| [YTsaurus](/engines/table-engines/integrations/ytsaurus) | The engine allows to import data from the YTsaurus cluster. |
| [Arrow Flight](/engines/table-engines/integrations/arrowflight) | The engine allows querying remote datasets via Apache Arrow Flight. |
<!--AUTOGENERATED_END-->
