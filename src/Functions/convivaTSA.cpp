#include <Columns/ColumnArray.h>
#include <Columns/ColumnString.h>
#include <DataTypes/DataTypeString.h>
#include <Functions/IFunction.h>
#include <Functions/FunctionFactory.h>

// Conviva timeline library
#include "compiler.h"
#include "executor.h"

namespace DB {

class FunctionConvivaTSA : public IFunction {
public:
    static constexpr auto name = "convivaTSA";
    static FunctionPtr create(const Context &) { return std::make_shared<FunctionConvivaTSA>(); }

    String getName() const override { return name; }

    size_t getNumberOfArguments() const override { return 2; } // We expect two arguments: data and compiled_plan

    bool isSuitableForShortCircuitArgumentsExecution(const DataTypesWithConstInfo & /*arguments*/) const override { return false; }

    DataTypePtr getReturnTypeImpl(const DataTypes & /*arguments*/) const override {
        // TODO: This function returns a json string including all metrics.
        //  We should expand to multiple columns either by UDTF or using another outer parsing query.
        return std::make_shared<DataTypeString>();
    }

    bool useDefaultImplementationForConstants() const override { return true; }

    ColumnPtr executeImpl(const ColumnsWithTypeAndName & arguments, const DataTypePtr &, size_t input_rows_count) const override {
        std::string yaml_string = (*arguments[1].column)[0].get<std::string>();  // Same yaml config for all rows in the block
        auto compiler = Compiler(yaml_string);
        compiler.compile();

        const auto & data_col = assert_cast<const ColumnArray &>(*arguments[0].column);
        const auto & values_col = assert_cast<const ColumnString &>(data_col.getData());
        auto result_col = ColumnString::create();

        for (size_t i = 0; i < input_rows_count; ++i) {
            // TODO: cache the compiled plan, also need to clear the DAG.
            // Initialize the executor with the physical plan
            auto physical_plan = compiler.getPhysicalPlan();
            auto executor = Executor(std::move(physical_plan));

            // Parse the array column. The offsets bound the range of elements in each row.
            std::vector<std::string> json_events;
            size_t begin = i > 0 ? data_col.getOffsets()[i - 1] : 0;
            size_t end = data_col.getOffsets()[i];
            for (size_t j = begin; j < end; ++j) {
                json_events.push_back(values_col.getDataAt(j).toString());
            }

            // Execute the plan
            executor.ingestStringEvents(json_events, "timestamp");
            auto result = executor.execute();
            // TODO: we can return the entire array and flatten it in the outer query for interval metrics.
            //  Essentially multiple rows can be generated by the DAG.
            result_col->insert(result[0]);
        }

        return result_col;
    }

private:
    std::unordered_map<std::string, std::unique_ptr<DAGNode>> dag_;  // Cache the compiled plan to avoid recompile
};

// Check this function registration: toUnixTimestamp64Micro.cpp
// For dependency management under contrib folder, check this simple example:
//   cat contrib/libmetrohash/CMakeLists.txt
//   grep -rl "metrohash" --include=CMakeLists.txt .
REGISTER_FUNCTION(ConvivaTSA)
{
    factory.registerFunction("convivaTSA",
                             [](ContextPtr){ return std::make_unique<FunctionToOverloadResolverAdaptor>(
                                   std::make_shared<FunctionConvivaTSA>()); });
}

} // namespace DB
