// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_MESSAGE_ORG_APACHE_ARROW_FLATBUF_H_
#define FLATBUFFERS_GENERATED_MESSAGE_ORG_APACHE_ARROW_FLATBUF_H_

#include "flatbuffers/flatbuffers.h"

#include "Schema_generated.h"
#include "SparseTensor_generated.h"
#include "Tensor_generated.h"

namespace org {
namespace apache {
namespace arrow {
namespace flatbuf {

struct FieldNode;

struct RecordBatch;

struct DictionaryBatch;

struct Message;

/// ----------------------------------------------------------------------
/// The root Message type
/// This union enables us to easily send different message types without
/// redundant storage, and in the future we can easily add new message types.
///
/// Arrow implementations do not need to implement all of the message types,
/// which may include experimental metadata types. For maximum compatibility,
/// it is best to send data using RecordBatch
enum MessageHeader {
  MessageHeader_NONE = 0,
  MessageHeader_Schema = 1,
  MessageHeader_DictionaryBatch = 2,
  MessageHeader_RecordBatch = 3,
  MessageHeader_Tensor = 4,
  MessageHeader_SparseTensor = 5,
  MessageHeader_MIN = MessageHeader_NONE,
  MessageHeader_MAX = MessageHeader_SparseTensor
};

inline const MessageHeader (&EnumValuesMessageHeader())[6] {
  static const MessageHeader values[] = {
    MessageHeader_NONE,
    MessageHeader_Schema,
    MessageHeader_DictionaryBatch,
    MessageHeader_RecordBatch,
    MessageHeader_Tensor,
    MessageHeader_SparseTensor
  };
  return values;
}

inline const char * const *EnumNamesMessageHeader() {
  static const char * const names[] = {
    "NONE",
    "Schema",
    "DictionaryBatch",
    "RecordBatch",
    "Tensor",
    "SparseTensor",
    nullptr
  };
  return names;
}

inline const char *EnumNameMessageHeader(MessageHeader e) {
  if (e < MessageHeader_NONE || e > MessageHeader_SparseTensor) return "";
  const size_t index = static_cast<size_t>(e);
  return EnumNamesMessageHeader()[index];
}

template<typename T> struct MessageHeaderTraits {
  static const MessageHeader enum_value = MessageHeader_NONE;
};

template<> struct MessageHeaderTraits<Schema> {
  static const MessageHeader enum_value = MessageHeader_Schema;
};

template<> struct MessageHeaderTraits<DictionaryBatch> {
  static const MessageHeader enum_value = MessageHeader_DictionaryBatch;
};

template<> struct MessageHeaderTraits<RecordBatch> {
  static const MessageHeader enum_value = MessageHeader_RecordBatch;
};

template<> struct MessageHeaderTraits<Tensor> {
  static const MessageHeader enum_value = MessageHeader_Tensor;
};

template<> struct MessageHeaderTraits<SparseTensor> {
  static const MessageHeader enum_value = MessageHeader_SparseTensor;
};

bool VerifyMessageHeader(flatbuffers::Verifier &verifier, const void *obj, MessageHeader type);
bool VerifyMessageHeaderVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types);

/// ----------------------------------------------------------------------
/// Data structures for describing a table row batch (a collection of
/// equal-length Arrow arrays)
/// Metadata about a field at some level of a nested type tree (but not
/// its children).
///
/// For example, a List<Int16> with values [[1, 2, 3], null, [4], [5, 6], null]
/// would have {length: 5, null_count: 2} for its List node, and {length: 6,
/// null_count: 0} for its Int16 node, as separate FieldNode structs
FLATBUFFERS_MANUALLY_ALIGNED_STRUCT(8) FieldNode FLATBUFFERS_FINAL_CLASS {
 private:
  int64_t length_;
  int64_t null_count_;

 public:
  FieldNode() {
    memset(static_cast<void *>(this), 0, sizeof(FieldNode));
  }
  FieldNode(int64_t _length, int64_t _null_count)
      : length_(flatbuffers::EndianScalar(_length)),
        null_count_(flatbuffers::EndianScalar(_null_count)) {
  }
  /// The number of value slots in the Arrow array at this level of a nested
  /// tree
  int64_t length() const {
    return flatbuffers::EndianScalar(length_);
  }
  /// The number of observed nulls. Fields with null_count == 0 may choose not
  /// to write their physical validity bitmap out as a materialized buffer,
  /// instead setting the length of the bitmap buffer to 0.
  int64_t null_count() const {
    return flatbuffers::EndianScalar(null_count_);
  }
};
FLATBUFFERS_STRUCT_END(FieldNode, 16);

/// A data header describing the shared memory layout of a "record" or "row"
/// batch. Some systems call this a "row batch" internally and others a "record
/// batch".
struct RecordBatch FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_LENGTH = 4,
    VT_NODES = 6,
    VT_BUFFERS = 8
  };
  /// number of records / rows. The arrays in the batch should all have this
  /// length
  int64_t length() const {
    return GetField<int64_t>(VT_LENGTH, 0);
  }
  /// Nodes correspond to the pre-ordered flattened logical schema
  const flatbuffers::Vector<const FieldNode *> *nodes() const {
    return GetPointer<const flatbuffers::Vector<const FieldNode *> *>(VT_NODES);
  }
  /// Buffers correspond to the pre-ordered flattened buffer tree
  ///
  /// The number of buffers appended to this list depends on the schema. For
  /// example, most primitive arrays will have 2 buffers, 1 for the validity
  /// bitmap and 1 for the values. For struct arrays, there will only be a
  /// single buffer for the validity (nulls) bitmap
  const flatbuffers::Vector<const Buffer *> *buffers() const {
    return GetPointer<const flatbuffers::Vector<const Buffer *> *>(VT_BUFFERS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int64_t>(verifier, VT_LENGTH) &&
           VerifyOffset(verifier, VT_NODES) &&
           verifier.VerifyVector(nodes()) &&
           VerifyOffset(verifier, VT_BUFFERS) &&
           verifier.VerifyVector(buffers()) &&
           verifier.EndTable();
  }
};

struct RecordBatchBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_length(int64_t length) {
    fbb_.AddElement<int64_t>(RecordBatch::VT_LENGTH, length, 0);
  }
  void add_nodes(flatbuffers::Offset<flatbuffers::Vector<const FieldNode *>> nodes) {
    fbb_.AddOffset(RecordBatch::VT_NODES, nodes);
  }
  void add_buffers(flatbuffers::Offset<flatbuffers::Vector<const Buffer *>> buffers) {
    fbb_.AddOffset(RecordBatch::VT_BUFFERS, buffers);
  }
  explicit RecordBatchBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  RecordBatchBuilder &operator=(const RecordBatchBuilder &);
  flatbuffers::Offset<RecordBatch> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<RecordBatch>(end);
    return o;
  }
};

inline flatbuffers::Offset<RecordBatch> CreateRecordBatch(
    flatbuffers::FlatBufferBuilder &_fbb,
    int64_t length = 0,
    flatbuffers::Offset<flatbuffers::Vector<const FieldNode *>> nodes = 0,
    flatbuffers::Offset<flatbuffers::Vector<const Buffer *>> buffers = 0) {
  RecordBatchBuilder builder_(_fbb);
  builder_.add_length(length);
  builder_.add_buffers(buffers);
  builder_.add_nodes(nodes);
  return builder_.Finish();
}

inline flatbuffers::Offset<RecordBatch> CreateRecordBatchDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    int64_t length = 0,
    const std::vector<FieldNode> *nodes = nullptr,
    const std::vector<Buffer> *buffers = nullptr) {
  auto nodes__ = nodes ? _fbb.CreateVectorOfStructs<FieldNode>(*nodes) : 0;
  auto buffers__ = buffers ? _fbb.CreateVectorOfStructs<Buffer>(*buffers) : 0;
  return org::apache::arrow::flatbuf::CreateRecordBatch(
      _fbb,
      length,
      nodes__,
      buffers__);
}

/// For sending dictionary encoding information. Any Field can be
/// dictionary-encoded, but in this case none of its children may be
/// dictionary-encoded.
/// There is one vector / column per dictionary, but that vector / column
/// may be spread across multiple dictionary batches by using the isDelta
/// flag
struct DictionaryBatch FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_ID = 4,
    VT_DATA = 6,
    VT_ISDELTA = 8
  };
  int64_t id() const {
    return GetField<int64_t>(VT_ID, 0);
  }
  const RecordBatch *data() const {
    return GetPointer<const RecordBatch *>(VT_DATA);
  }
  /// If isDelta is true the values in the dictionary are to be appended to a
  /// dictionary with the indicated id
  bool isDelta() const {
    return GetField<uint8_t>(VT_ISDELTA, 0) != 0;
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int64_t>(verifier, VT_ID) &&
           VerifyOffset(verifier, VT_DATA) &&
           verifier.VerifyTable(data()) &&
           VerifyField<uint8_t>(verifier, VT_ISDELTA) &&
           verifier.EndTable();
  }
};

struct DictionaryBatchBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_id(int64_t id) {
    fbb_.AddElement<int64_t>(DictionaryBatch::VT_ID, id, 0);
  }
  void add_data(flatbuffers::Offset<RecordBatch> data) {
    fbb_.AddOffset(DictionaryBatch::VT_DATA, data);
  }
  void add_isDelta(bool isDelta) {
    fbb_.AddElement<uint8_t>(DictionaryBatch::VT_ISDELTA, static_cast<uint8_t>(isDelta), 0);
  }
  explicit DictionaryBatchBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  DictionaryBatchBuilder &operator=(const DictionaryBatchBuilder &);
  flatbuffers::Offset<DictionaryBatch> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<DictionaryBatch>(end);
    return o;
  }
};

inline flatbuffers::Offset<DictionaryBatch> CreateDictionaryBatch(
    flatbuffers::FlatBufferBuilder &_fbb,
    int64_t id = 0,
    flatbuffers::Offset<RecordBatch> data = 0,
    bool isDelta = false) {
  DictionaryBatchBuilder builder_(_fbb);
  builder_.add_id(id);
  builder_.add_data(data);
  builder_.add_isDelta(isDelta);
  return builder_.Finish();
}

struct Message FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_VERSION = 4,
    VT_HEADER_TYPE = 6,
    VT_HEADER = 8,
    VT_BODYLENGTH = 10,
    VT_CUSTOM_METADATA = 12
  };
  MetadataVersion version() const {
    return static_cast<MetadataVersion>(GetField<int16_t>(VT_VERSION, 0));
  }
  MessageHeader header_type() const {
    return static_cast<MessageHeader>(GetField<uint8_t>(VT_HEADER_TYPE, 0));
  }
  const void *header() const {
    return GetPointer<const void *>(VT_HEADER);
  }
  template<typename T> const T *header_as() const;
  const Schema *header_as_Schema() const {
    return header_type() == MessageHeader_Schema ? static_cast<const Schema *>(header()) : nullptr;
  }
  const DictionaryBatch *header_as_DictionaryBatch() const {
    return header_type() == MessageHeader_DictionaryBatch ? static_cast<const DictionaryBatch *>(header()) : nullptr;
  }
  const RecordBatch *header_as_RecordBatch() const {
    return header_type() == MessageHeader_RecordBatch ? static_cast<const RecordBatch *>(header()) : nullptr;
  }
  const Tensor *header_as_Tensor() const {
    return header_type() == MessageHeader_Tensor ? static_cast<const Tensor *>(header()) : nullptr;
  }
  const SparseTensor *header_as_SparseTensor() const {
    return header_type() == MessageHeader_SparseTensor ? static_cast<const SparseTensor *>(header()) : nullptr;
  }
  int64_t bodyLength() const {
    return GetField<int64_t>(VT_BODYLENGTH, 0);
  }
  const flatbuffers::Vector<flatbuffers::Offset<KeyValue>> *custom_metadata() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<KeyValue>> *>(VT_CUSTOM_METADATA);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int16_t>(verifier, VT_VERSION) &&
           VerifyField<uint8_t>(verifier, VT_HEADER_TYPE) &&
           VerifyOffset(verifier, VT_HEADER) &&
           VerifyMessageHeader(verifier, header(), header_type()) &&
           VerifyField<int64_t>(verifier, VT_BODYLENGTH) &&
           VerifyOffset(verifier, VT_CUSTOM_METADATA) &&
           verifier.VerifyVector(custom_metadata()) &&
           verifier.VerifyVectorOfTables(custom_metadata()) &&
           verifier.EndTable();
  }
};

template<> inline const Schema *Message::header_as<Schema>() const {
  return header_as_Schema();
}

template<> inline const DictionaryBatch *Message::header_as<DictionaryBatch>() const {
  return header_as_DictionaryBatch();
}

template<> inline const RecordBatch *Message::header_as<RecordBatch>() const {
  return header_as_RecordBatch();
}

template<> inline const Tensor *Message::header_as<Tensor>() const {
  return header_as_Tensor();
}

template<> inline const SparseTensor *Message::header_as<SparseTensor>() const {
  return header_as_SparseTensor();
}

struct MessageBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_version(MetadataVersion version) {
    fbb_.AddElement<int16_t>(Message::VT_VERSION, static_cast<int16_t>(version), 0);
  }
  void add_header_type(MessageHeader header_type) {
    fbb_.AddElement<uint8_t>(Message::VT_HEADER_TYPE, static_cast<uint8_t>(header_type), 0);
  }
  void add_header(flatbuffers::Offset<void> header) {
    fbb_.AddOffset(Message::VT_HEADER, header);
  }
  void add_bodyLength(int64_t bodyLength) {
    fbb_.AddElement<int64_t>(Message::VT_BODYLENGTH, bodyLength, 0);
  }
  void add_custom_metadata(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<KeyValue>>> custom_metadata) {
    fbb_.AddOffset(Message::VT_CUSTOM_METADATA, custom_metadata);
  }
  explicit MessageBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MessageBuilder &operator=(const MessageBuilder &);
  flatbuffers::Offset<Message> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Message>(end);
    return o;
  }
};

inline flatbuffers::Offset<Message> CreateMessage(
    flatbuffers::FlatBufferBuilder &_fbb,
    MetadataVersion version = MetadataVersion_V1,
    MessageHeader header_type = MessageHeader_NONE,
    flatbuffers::Offset<void> header = 0,
    int64_t bodyLength = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<KeyValue>>> custom_metadata = 0) {
  MessageBuilder builder_(_fbb);
  builder_.add_bodyLength(bodyLength);
  builder_.add_custom_metadata(custom_metadata);
  builder_.add_header(header);
  builder_.add_version(version);
  builder_.add_header_type(header_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Message> CreateMessageDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    MetadataVersion version = MetadataVersion_V1,
    MessageHeader header_type = MessageHeader_NONE,
    flatbuffers::Offset<void> header = 0,
    int64_t bodyLength = 0,
    const std::vector<flatbuffers::Offset<KeyValue>> *custom_metadata = nullptr) {
  auto custom_metadata__ = custom_metadata ? _fbb.CreateVector<flatbuffers::Offset<KeyValue>>(*custom_metadata) : 0;
  return org::apache::arrow::flatbuf::CreateMessage(
      _fbb,
      version,
      header_type,
      header,
      bodyLength,
      custom_metadata__);
}

inline bool VerifyMessageHeader(flatbuffers::Verifier &verifier, const void *obj, MessageHeader type) {
  switch (type) {
    case MessageHeader_NONE: {
      return true;
    }
    case MessageHeader_Schema: {
      auto ptr = reinterpret_cast<const Schema *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case MessageHeader_DictionaryBatch: {
      auto ptr = reinterpret_cast<const DictionaryBatch *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case MessageHeader_RecordBatch: {
      auto ptr = reinterpret_cast<const RecordBatch *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case MessageHeader_Tensor: {
      auto ptr = reinterpret_cast<const Tensor *>(obj);
      return verifier.VerifyTable(ptr);
    }
    case MessageHeader_SparseTensor: {
      auto ptr = reinterpret_cast<const SparseTensor *>(obj);
      return verifier.VerifyTable(ptr);
    }
    default: return false;
  }
}

inline bool VerifyMessageHeaderVector(flatbuffers::Verifier &verifier, const flatbuffers::Vector<flatbuffers::Offset<void>> *values, const flatbuffers::Vector<uint8_t> *types) {
  if (!values || !types) return !values && !types;
  if (values->size() != types->size()) return false;
  for (flatbuffers::uoffset_t i = 0; i < values->size(); ++i) {
    if (!VerifyMessageHeader(
        verifier,  values->Get(i), types->GetEnum<MessageHeader>(i))) {
      return false;
    }
  }
  return true;
}

inline const org::apache::arrow::flatbuf::Message *GetMessage(const void *buf) {
  return flatbuffers::GetRoot<org::apache::arrow::flatbuf::Message>(buf);
}

inline const org::apache::arrow::flatbuf::Message *GetSizePrefixedMessage(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<org::apache::arrow::flatbuf::Message>(buf);
}

inline bool VerifyMessageBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<org::apache::arrow::flatbuf::Message>(nullptr);
}

inline bool VerifySizePrefixedMessageBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<org::apache::arrow::flatbuf::Message>(nullptr);
}

inline void FinishMessageBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<org::apache::arrow::flatbuf::Message> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedMessageBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<org::apache::arrow::flatbuf::Message> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace flatbuf
}  // namespace arrow
}  // namespace apache
}  // namespace org

#endif  // FLATBUFFERS_GENERATED_MESSAGE_ORG_APACHE_ARROW_FLATBUF_H_
