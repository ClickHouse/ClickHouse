-- Tags: no-debug, long
-- - no-debug - debug build uses S3 and this in combination works very slow

-- Note, all tests avoids vertical merges (enable_vertical_merge_algorithm=0), since they write column by column and do not have excessive memory usage.

drop table if exists metric_log;
drop table if exists metric_log_adaptive;

-- Nothing better then production table
system flush logs system.metric_log;

{% for v in [0, 1] %}
create table metric_log_{{ v }} as system.metric_log engine=MergeTree order by () settings min_columns_to_activate_adaptive_write_buffer={{ v }}, min_bytes_for_wide_part=1e9, enable_vertical_merge_algorithm=0, auto_statistics_types='';
insert into metric_log_{{ v }} select * from generateRandom() limit 1 settings max_memory_usage = '100Mi' /* usually few tens of MiB */;
optimize table metric_log_{{ v }} final;
truncate table metric_log_{{ v }};
alter table metric_log_{{ v }} modify setting min_bytes_for_wide_part=0;
insert into metric_log_{{ v }} select * from generateRandom() limit 1 settings max_memory_usage = '{{ 200 if v == 1 else 4000 }}Mi' /* w/o adaptive buffers uses ~3, w/ 150MiB */;
optimize table metric_log_{{ v }} final;
drop table metric_log_{{ v }};
{% endfor %}

-- Flush system tables all at once
system flush logs part_log;
select
  table,
  part_type,
  merge_algorithm,
  max2(
    peak_memory_usage,
    multiIf(
      part_type = 'Compact', 200e6,
      table = 'metric_log_1', 200e6,
      table = 'metric_log_0', 4e9,
      0.
    )
  )
from system.part_log
where database = currentDatabase() and event_type = 'MergeParts'
order by event_time_microseconds;
