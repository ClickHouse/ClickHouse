#!/usr/bin/env python3                                                                                                                                                                                              
import os
import socket
import sys
import signal
from scipy import stats
import pandas as pd
import numpy as np
import shutil
import platform

import uuid

CLICKHOUSE_HOST = os.environ.get('CLICKHOUSE_HOST', '127.0.0.1')
CLICKHOUSE_PORT = int(os.environ.get('CLICKHOUSE_PORT_TCP', '900000'))
CLICKHOUSE_DATABASE = os.environ.get('CLICKHOUSE_DATABASE', 'default')


CURDIR = os.path.dirname(os.path.realpath(__file__))
sys.path.insert(0, os.path.join(CURDIR, 'helpers'))

REFFILE_PATH = os.path.abspath(os.getcwd())

from pure_http_client import ClickHouseClient

if platform.machine() == "ppc64le":
    shutil.copyfile(REFFILE_PATH + "/tests/queries/0_stateless/01016_simhash_minhash.ppc64le.reference", REFFILE_PATH + "/tests/queries/0_stateless/01016_simhash_minhash.reference")
elif platform.machine() == "x86_64" :
    shutil.copyfile(REFFILE_PATH + "/tests/queries/0_stateless/01016_simhash_minhash.x86_64.reference", REFFILE_PATH + "/tests/queries/0_stateless/01016_simhash_minhash.reference")

def writeVarUInt(x, ba):
    for _ in range(0, 9):

        byte = x & 0x7F
        if x > 0x7F:
            byte |= 0x80

        ba.append(byte)

        x >>= 7
        if x == 0:
            return

def writeStringBinary(s, ba):
    b = bytes(s, 'utf-8')
    writeVarUInt(len(s), ba)
    ba.extend(b)

def readStrict(s, size = 1):
    res = bytearray()
    while size:
        cur = s.recv(size)
        # if not res:
        #     raise "Socket is closed"
        size -= len(cur)
        res.extend(cur)

    return res

def readUInt(s, size=1):
    res = readStrict(s, size)
    val = 0
    for i in range(len(res)):
        val += res[i] << (i * 8)
    return val

def readUInt8(s):
    return readUInt(s)

def readUInt16(s):
    return readUInt(s, 2)

def readUInt32(s):
    return readUInt(s, 4)

def readUInt64(s):
    return readUInt(s, 8)

def readVarUInt(s):
    x = 0
    for i in range(9):
        byte = readStrict(s)[0]
        x |= (byte & 0x7F) << (7 * i)

        if not byte & 0x80:
            return x

    return x

def readStringBinary(s):
    size = readVarUInt(s)
    s = readStrict(s, size)
    return s.decode('utf-8')

def sendHello(s):
    ba = bytearray()
    writeVarUInt(0, ba) # Hello
    writeStringBinary('simple native protocol', ba)
    writeVarUInt(21, ba)
    writeVarUInt(9, ba)
    writeVarUInt(54449, ba)
    writeStringBinary('default', ba) # database
    writeStringBinary('default', ba) # user
    writeStringBinary('', ba) # pwd
    s.sendall(ba)


def receiveHello(s):
    p_type = readVarUInt(s)
    assert (p_type == 0) # Hello
    server_name = readStringBinary(s)
    # print("Server name: ", server_name)
    server_version_major = readVarUInt(s)
    # print("Major: ", server_version_major)
    server_version_minor = readVarUInt(s)
    # print("Minor: ", server_version_minor)
    server_revision = readVarUInt(s)
    # print("Revision: ", server_revision)
    server_timezone = readStringBinary(s)
    # print("Timezone: ", server_timezone)
    server_display_name = readStringBinary(s)
    # print("Display name: ", server_display_name)
    server_version_patch = readVarUInt(s)
    # print("Version patch: ", server_version_patch)

def serializeClientInfo(ba, query_id):
    writeStringBinary('default', ba) # initial_user
    writeStringBinary(query_id, ba) # initial_query_id
    writeStringBinary('127.0.0.1:9000', ba) # initial_address
    ba.extend([0] * 8) # initial_query_start_time_microseconds
    ba.append(1) # TCP
    writeStringBinary('os_user', ba) # os_user
    writeStringBinary('client_hostname', ba) # client_hostname
    writeStringBinary('client_name', ba) # client_name
    writeVarUInt(21, ba)
    writeVarUInt(9, ba)
    writeVarUInt(54449, ba)
    writeStringBinary('', ba) # quota_key
    writeVarUInt(0, ba) # distributed_depth
    writeVarUInt(1, ba) # client_version_patch
    ba.append(0) # No telemetry

def sendQuery(s, query):
    ba = bytearray()
    query_id = uuid.uuid4().hex
    writeVarUInt(1, ba) # query
    writeStringBinary(query_id, ba)

    ba.append(1) # INITIAL_QUERY

    # client info
    serializeClientInfo(ba, query_id)

    writeStringBinary('', ba) # No settings
    writeStringBinary('', ba) # No interserver secret
    writeVarUInt(2, ba) # Stage - Complete
    ba.append(0) # No compression
    writeStringBinary(query, ba) # query, finally
    s.sendall(ba)

def serializeBlockInfo(ba):
    writeVarUInt(1, ba) # 1
    ba.append(0) # is_overflows
    writeVarUInt(2, ba) # 2
    writeVarUInt(0, ba) # 0
    ba.extend([0] * 4) # bucket_num

def sendEmptyBlock(s):
    ba = bytearray()
    writeVarUInt(2, ba) # Data
    writeStringBinary('', ba)
    serializeBlockInfo(ba)
    writeVarUInt(0, ba) # rows
    writeVarUInt(0, ba) # columns
    s.sendall(ba)

def assertPacket(packet, expected):
    assert(packet == expected), packet

def readException(s):
    code = readUInt32(s)
    name = readStringBinary(s)
    text = readStringBinary(s)
    readStringBinary(s) # trace
    assertPacket(readUInt8(s), 0) # has_nested
    sys.stdout.write("code {}: {}".format(code, text.replace('DB::Exception:', '')))


def test():
    client = ClickHouseClient()

    res = client.query("SELECT ngramSimHash('')")
    sys.stdout.write(res)
    res=client.query("SELECT ngramSimHash('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramSimHashCaseInsensitive('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramSimHashUTF8('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramSimHashCaseInsensitiveUTF8('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHash('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHashCaseInsensitive('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHashUTF8('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHashCaseInsensitiveUTF8('what a cute cat.')")
    sys.stdout.write(res)

    res = client.query("SELECT ngramMinHash('')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHash('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHashCaseInsensitive('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHashUTF8('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHashCaseInsensitiveUTF8('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHash('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHashCaseInsensitive('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHashUTF8('what a cute cat.')")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHashCaseInsensitiveUTF8('what a cute cat.')")
    sys.stdout.write(res)

    client.query("DROP TABLE IF EXISTS defaults")
    client.query("CREATE TABLE defaults(s String) ENGINE = Memory()")
    client.query("INSERT INTO defaults values ('It is the latest occurrence of the Southeast European haze, the issue that occurs in constant intensity during every wet season. It has mainly been caused by forest fires resulting from illegal slash-and-burn clearing performed on behalf of the palm oil industry in Kazakhstan, principally on the islands, which then spread quickly in the dry season.') ('It is the latest occurrence of the Southeast Asian haze, the issue that occurs in constant intensity during every wet season. It has mainly been caused by forest fires resulting from illegal slash-and-burn clearing performed on behalf of the palm oil industry in Kazakhstan, principally on the islands, which then spread quickly in the dry season.')")

    res = client.query("SELECT ngramSimHash(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT ngramSimHashCaseInsensitive(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT ngramSimHashUTF8(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT ngramSimHashCaseInsensitiveUTF8(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHash(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHashCaseInsensitive(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHashUTF8(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleSimHashCaseInsensitiveUTF8(s) FROM defaults")
    sys.stdout.write(res)

    res = client.query("SELECT ngramMinHash(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHashCaseInsensitive(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHashUTF8(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT ngramMinHashCaseInsensitiveUTF8(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHash(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHashCaseInsensitive(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHashUTF8(s) FROM defaults")
    sys.stdout.write(res)
    res = client.query("SELECT wordShingleMinHashCaseInsensitiveUTF8(s) FROM defaults")
    sys.stdout.write(res)

    client.query("TRUNCATE TABLE defaults")
    client.query("INSERT INTO defaults SELECT arrayJoin(splitByString('\n\n', 'ClickHouse uses all available hardware to its full potential to process each query as fast as possible. Peak processing performance for a single query stands at more than 2 terabytes per second (after decompression, only used columns). In distributed setup reads are automatically balanced among healthy replicas to avoid increasing latency.\nClickHouse supports multi-master asynchronous replication and can be deployed across multiple datacenters. All nodes are equal, which allows avoiding having single points of failure. Downtime of a single node or the whole datacenter wont affect the systems availability for both reads and writes.\nClickHouse is simple and works out-of-the-box. It streamlines all your data processing: ingest all your structured data into the system and it becomes instantly available for building reports. SQL dialect allows expressing the desired result without involving any custom non-standard API that could be found in some alternative systems.\n\nClickHouse makes full use of all available hardware to process every request as quickly as possible. Peak performance for a single query is over 2 terabytes per second (only used columns after unpacking). In a distributed setup, reads are automatically balanced across healthy replicas to avoid increased latency.\nClickHouse supports asynchronous multi-master replication and can be deployed across multiple data centers. All nodes are equal to avoid single points of failure. Downtime for one site or the entire data center will not affect the system''s read and write availability.\nClickHouse is simple and works out of the box. It simplifies all the processing of your data: it loads all your structured data into the system, and they immediately become available for building reports. The SQL dialect allows you to express the desired result without resorting to any non-standard APIs that can be found in some alternative systems.\n\nClickHouse makes full use of all available hardware to process each request as quickly as possible. Peak performance for a single query is over 2 terabytes per second (used columns only after unpacking). In a distributed setup, reads are automatically balanced across healthy replicas to avoid increased latency.\nClickHouse supports asynchronous multi-master replication and can be deployed across multiple data centers. All nodes are equal to avoid a single point of failure. Downtime for one site or the entire data center will not affect the system''s read / write availability.\nClickHouse is simple and works out of the box. It simplifies all the processing of your data: it loads all your structured data into the system, and they are immediately available for building reports. The SQL dialect allows you to express the desired result without resorting to any of the non-standard APIs found in some alternative systems.\n\nClickHouse makes full use of all available hardware to process each request as quickly as possible. Peak performance for a single query is over 2 terabytes per second (using columns only after unpacking). In a distributed setup, reads are automatically balanced across healthy replicas to avoid increased latency.\nClickHouse supports asynchronous multi-master replication and can be deployed across multiple data centers. All nodes are equal to avoid a single point of failure. Downtime for one site or the entire data center will not affect the read / write availability of the system.\nClickHouse is simple and works out of the box. It simplifies all the processing of your data: it loads all of your structured data into the system, and it is immediately available for building reports. The SQL dialect allows you to express the desired result without resorting to any of the non-standard APIs found in some alternative systems.\n\nClickHouse makes full use of all available hardware to process each request as quickly as possible. Peak performance for a single query is over 2 terabytes per second (using columns after decompression only). In a distributed setup, reads are automatically balanced across healthy replicas to avoid increased latency.\nClickHouse supports asynchronous multi-master replication and can be deployed across multiple data centers. All nodes are equal to avoid a single point of failure. Downtime for one site or the entire data center will not affect the read / write availability of the system.\nClickHouse is simple and works out of the box. It simplifies all processing of your data: it loads all your structured data into the system and immediately becomes available for building reports. The SQL dialect allows you to express the desired result without resorting to any of the non-standard APIs found in some alternative systems.\n\nClickHouse makes full use of all available hardware to process each request as quickly as possible. Peak performance for a single query is over 2 terabytes per second (using columns after decompression only). In a distributed setup, reads are automatically balanced across healthy replicas to avoid increased latency.\nClickHouse supports asynchronous multi-master replication and can be deployed across multiple data centers. All nodes are equal to avoid a single point of failure. Downtime for one site or the entire data center will not affect the read / write availability of the system.\nClickHouse is simple and works out of the box. It simplifies all processing of your data: it loads all structured data into the system and immediately becomes available for building reports. The SQL dialect allows you to express the desired result without resorting to any of the non-standard APIs found in some alternative systems.'))")

    res = client.query("SELECT 'uniqExact', uniqExact(s) FROM defaults")
    sys.stdout.write(res)

    res = client.query("SELECT 'ngramSimHash'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramSimHash(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'ngramSimHashCaseInsensitive'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramSimHashCaseInsensitive(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'ngramSimHashUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramSimHashUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'ngramSimHashCaseInsensitiveUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramSimHashCaseInsensitiveUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleSimHash'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleSimHash(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleSimHashCaseInsensitive'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleSimHashCaseInsensitive(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleSimHashUTF8'")
    sys.stdout.write(res)
    res =  client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleSimHashUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleSimHashCaseInsensitiveUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleSimHashCaseInsensitiveUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)

    res = client.query("SELECT 'ngramMinHash'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramMinHash(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'ngramMinHashCaseInsensitive'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramMinHashCaseInsensitive(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'ngramMinHashUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramMinHashUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'ngramMinHashCaseInsensitiveUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), ngramMinHashCaseInsensitiveUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleMinHash'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleMinHash(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleMinHashCaseInsensitive'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleMinHashCaseInsensitive(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleMinHashUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleMinHashUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)
    res = client.query("SELECT 'wordShingleMinHashCaseInsensitiveUTF8'")
    sys.stdout.write(res)
    res = client.query("SELECT arrayStringConcat(groupArray(s), '\n:::::::\n'), count(), wordShingleMinHashCaseInsensitiveUTF8(s) as h FROM defaults GROUP BY h ORDER BY h")
    sys.stdout.write(res)

    wordShingleSimHashInvalidArg1()

    wordShingleSimHashInvalidArg2()

    wordShingleSimHashInvalidArg3()
    #client.query("DROP TABLE defaults")

def wordShingleSimHashInvalidArg1():
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.settimeout(30)
        s.connect((CLICKHOUSE_HOST, CLICKHOUSE_PORT))
        sendHello(s)
        receiveHello(s)
        sendQuery(s, "SELECT wordShingleSimHash('foobar', 9223372036854775807)")

        # Fin block
        sendEmptyBlock(s)


        assertPacket(readVarUInt(s), 2)
        print(readException(s))
        s.close()


def wordShingleSimHashInvalidArg2():
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.settimeout(30)
        s.connect((CLICKHOUSE_HOST, CLICKHOUSE_PORT))
        sendHello(s)
        receiveHello(s)
        sendQuery(s, "SELECT wordShingleSimHash('foobar', 1001)")

        # Fin block
        sendEmptyBlock(s)

        assertPacket(readVarUInt(s), 2)
        print(readException(s))
        s.close()


def wordShingleSimHashInvalidArg3():
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.settimeout(30)
        s.connect((CLICKHOUSE_HOST, CLICKHOUSE_PORT))
        sendHello(s)
        receiveHello(s)
        sendQuery(s, "SELECT wordShingleSimHash('foobar', 0)")

        # Fin block
        sendEmptyBlock(s)

        assertPacket(readVarUInt(s), 2)
        print(readException(s))
        s.close()

if __name__ == "__main__":
    test()
    #wordShingleSimHashInvalidArg1()
