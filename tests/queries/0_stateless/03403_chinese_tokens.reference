Chinese tokenizer
-- coarse_grained (default)
[]
['他','来到','了','网易','杭研','大厦']
['我','来自','北京邮电大学']
['南京市','长江大桥']
['我','来自','北京邮电大学','学号','123456']
['小明','硕士','毕业','于','中国科学院','计算所','后','在','日本京都大学','深造']
-- coarse_grained
[]
['他','来到','了','网易','杭研','大厦']
['我','来自','北京邮电大学']
['南京市','长江大桥']
['我','来自','北京邮电大学','学号','123456']
['小明','硕士','毕业','于','中国科学院','计算所','后','在','日本京都大学','深造']
-- fine_grained
[]
['他','来到','了','网易','杭','研','大厦']
['我','来自','北京','北京邮电','北京邮电大学','邮电','邮电大学','电大','大学']
['南京','南京市','京市','市长','长江','长江大桥','大桥']
['我','来自','北京','北京邮电','北京邮电大学','邮电','邮电大学','电大','大学','学号','1','2','3','4','5','6']
['小','明','硕士','毕业','于','中国','中国科学院','科学','科学院','学院','计算','计算所','后','在','日本','日本京都大学','京都','京都大学','大学','深造']
